{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to train the model\n",
    "\n",
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 3038,
     "status": "ok",
     "timestamp": 1604407303984,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "6OQ6183NbJ2h"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#import require library for the data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer,HashingVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32888,
     "status": "ok",
     "timestamp": 1604407334671,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "E642rM2KbPb6",
    "outputId": "1fc865d0-caaa-4266-c95e-61ac72d4c494"
   },
   "outputs": [],
   "source": [
    "#make connection to the google drive\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 2744,
     "status": "ok",
     "timestamp": 1604407342378,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "4HQ7CxjubJ2p"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0  Layin n bed with a headache  ughhhh...waitin o...   sadness\n",
       "1                Funeral ceremony...gloomy friday...   sadness\n",
       "2  Re-pinging @ghostridah14: why didn't you go to...     worry\n",
       "3  I should be sleep, but im not! thinking about ...   sadness\n",
       "4               Hmmm. http://www.djhero.com/ is down     worry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\t\t\tChecking the value count for sentiment\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sadness      8995\n",
       "worry        8459\n",
       "joy          8240\n",
       "surprise     6036\n",
       "happiness    5209\n",
       "love         3842\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#read data from the drive\n",
    "#data = pd.read_csv('/content/drive/My Drive/emotion_detector/emotion.csv')\n",
    "data = pd.read_csv('tweets_data.csv')\n",
    "del data['Unnamed: 0']\n",
    "#del data['Unnamed: 0.1']\n",
    "display(data.head())\n",
    "\n",
    "#Checking the values count for sentiment\n",
    "print(\"-\"*80)\n",
    "print ('\\t\\t\\tChecking the value count for sentiment')\n",
    "print(\"-\"*80)\n",
    "display(data.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del data['Unnamed: 0']\n",
    "#del data['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 749,
     "status": "ok",
     "timestamp": 1604382658223,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "Cumk2DMSbJ2w",
    "outputId": "e669dc47-1dcb-4671-d40f-e06e95fb0819"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "\t\t describe data by object\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "                                                  content sentiment\n",
      "count                                               40781     40781\n",
      "unique                                              40522         6\n",
      "top     RT, follow @unitednude and WIN one of the 5 sp...   sadness\n",
      "freq                                                   35      8995\n"
     ]
    }
   ],
   "source": [
    "#describe data\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print (\"\\t\\t describe data by object\")\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "print(data.describe(include = [np.object]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code remove extra words and link from the dataset\n",
    "data['content']=data['content'].str.replace('[^A-Za-z0-9\\s]+', '')\n",
    "data['content']=data['content'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Funeral ceremonygloomy friday</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Repinging ghostridah14 why didnt you go to pro...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I should be sleep but im not thinking about an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hmmm  is down</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0  Layin n bed with a headache  ughhhhwaitin on y...   sadness\n",
       "1                      Funeral ceremonygloomy friday   sadness\n",
       "2  Repinging ghostridah14 why didnt you go to pro...     worry\n",
       "3  I should be sleep but im not thinking about an...   sadness\n",
       "4                                      Hmmm  is down     worry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code convert all dataset into small case\n",
    "for x in data:\n",
    "    if data[x].dtype == object:\n",
    "        #remove extra whitespace\n",
    "        data[x] = data[x].str.strip()\n",
    "        #convert into lowercase\n",
    "        data[x] = data[x].str.lower()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      "\t\t Tweets dataset for emotion\n",
      "\n",
      "------------------------------------------------------------\n",
      "\n",
      " Tweets data size 81562  ||  Shape: (40781, 2)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repinging ghostridah14 why didnt you go to pro...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i should be sleep but im not thinking about an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hmmm  is down</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0  layin n bed with a headache  ughhhhwaitin on y...   sadness\n",
       "1                      funeral ceremonygloomy friday   sadness\n",
       "2  repinging ghostridah14 why didnt you go to pro...     worry\n",
       "3  i should be sleep but im not thinking about an...   sadness\n",
       "4                                      hmmm  is down     worry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40776</th>\n",
       "      <td>about to have a movie night with my booboo jel...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40777</th>\n",
       "      <td>thebodyshopuk knowing my dissertation will be ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40778</th>\n",
       "      <td>hospital tomorrow morning strapped with wires ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40779</th>\n",
       "      <td>work is soooo slow ready to have a great saturday</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40780</th>\n",
       "      <td>you realize that by choosing joy every single ...</td>\n",
       "      <td>joy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 content sentiment\n",
       "40776  about to have a movie night with my booboo jel...   sadness\n",
       "40777  thebodyshopuk knowing my dissertation will be ...       joy\n",
       "40778  hospital tomorrow morning strapped with wires ...       joy\n",
       "40779  work is soooo slow ready to have a great saturday       joy\n",
       "40780  you realize that by choosing joy every single ...       joy"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "\t\t\tChecking the Duplicate data\n",
      "--------------------------------------------------------------------------------\n",
      "Data size with duplicate value: 81562  ||  Shape: (40781, 2)\n",
      "\n",
      "Is there any Duplicate value? \n",
      "True\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\t\t\tChecking the null values\n",
      "--------------------------------------------------------------------------------\n",
      "content      0\n",
      "sentiment    0\n",
      "dtype: int64\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sadness      8995\n",
       "worry        8459\n",
       "joy          8240\n",
       "surprise     6036\n",
       "happiness    5209\n",
       "love         3842\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Code to check duplicate and null value and remove it\n",
    "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "print (\"\\t\\t Tweets dataset for emotion\")\n",
    "print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "print (\" Tweets data size \" + str(data.size) + \"  ||  Shape: \" + str(data.shape) + \"\\n\")\n",
    "display(data.head())\n",
    "display(data.tail())\n",
    "\n",
    "#Checking the Duplicate data\n",
    "print(\"-\"*80)\n",
    "print ('\\t\\t\\tChecking the Duplicate data')\n",
    "print(\"-\"*80)\n",
    "\n",
    "#display the data size before dropping duplicate\n",
    "print (\"Data size with duplicate value: \" + str(data.size) + \"  ||  Shape: \" + str(data.shape) + \"\\n\")\n",
    "print ('Is there any Duplicate value? ') \n",
    "print (str(data.duplicated().any()) + \"\\n\") #check the duplicate value\n",
    "\n",
    "#Checking the null values\n",
    "print(\"-\"*80)\n",
    "print ('\\t\\t\\tChecking the null values')\n",
    "print(\"-\"*80)\n",
    "\n",
    "#check null values\n",
    "print (data.isnull().sum())\n",
    "print(\"-\"*80)\n",
    "\n",
    "display(data.sentiment.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repinging ghostridah14 why didnt you go to pro...</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i should be sleep but im not thinking about an...</td>\n",
       "      <td>sadness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hmmm  is down</td>\n",
       "      <td>worry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment\n",
       "0  layin n bed with a headache  ughhhhwaitin on y...   sadness\n",
       "1                      funeral ceremonygloomy friday   sadness\n",
       "2  repinging ghostridah14 why didnt you go to pro...     worry\n",
       "3  i should be sleep but im not thinking about an...   sadness\n",
       "4                                      hmmm  is down     worry"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use English stemmer.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Sentences to be stemmed.\n",
    "#data = [\"programers program with programing languages\", \"my code is working so there must be a bug in the optimizer\"] \n",
    "    \n",
    "# Create the Pandas dataFrame.\n",
    "#df = pd.DataFrame(data, columns = ['unstemmed']) \n",
    "\n",
    "# Split the sentences to lists of words.\n",
    "data['unstemmed'] = data['content'].str.split()\n",
    "\n",
    "data['stemmed'] = data['unstemmed'].apply(lambda x: [stemmer.stem(y) for y in x]) # Stem every word.\n",
    "#df = df.drop(columns=['unstemmed']) # Get rid of the unstemmed column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhhwaiti...</td>\n",
       "      <td>[layin, n, bed, with, a, headach, ughhhhwaitin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funer, ceremonygloomi, friday]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repinging ghostridah14 why didnt you go to pro...</td>\n",
       "      <td>worry</td>\n",
       "      <td>[repinging, ghostridah14, why, didnt, you, go,...</td>\n",
       "      <td>[reping, ghostridah14, whi, didnt, you, go, to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i should be sleep but im not thinking about an...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[i, should, be, sleep, but, im, not, thinking,...</td>\n",
       "      <td>[i, should, be, sleep, but, im, not, think, ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hmmm  is down</td>\n",
       "      <td>worry</td>\n",
       "      <td>[hmmm, is, down]</td>\n",
       "      <td>[hmmm, is, down]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment  \\\n",
       "0  layin n bed with a headache  ughhhhwaitin on y...   sadness   \n",
       "1                      funeral ceremonygloomy friday   sadness   \n",
       "2  repinging ghostridah14 why didnt you go to pro...     worry   \n",
       "3  i should be sleep but im not thinking about an...   sadness   \n",
       "4                                      hmmm  is down     worry   \n",
       "\n",
       "                                           unstemmed  \\\n",
       "0  [layin, n, bed, with, a, headache, ughhhhwaiti...   \n",
       "1                  [funeral, ceremonygloomy, friday]   \n",
       "2  [repinging, ghostridah14, why, didnt, you, go,...   \n",
       "3  [i, should, be, sleep, but, im, not, thinking,...   \n",
       "4                                   [hmmm, is, down]   \n",
       "\n",
       "                                             stemmed  \n",
       "0  [layin, n, bed, with, a, headach, ughhhhwaitin...  \n",
       "1                    [funer, ceremonygloomi, friday]  \n",
       "2  [reping, ghostridah14, whi, didnt, you, go, to...  \n",
       "3  [i, should, be, sleep, but, im, not, think, ab...  \n",
       "4                                   [hmmm, is, down]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6926,
     "status": "ok",
     "timestamp": 1604407766817,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "J7nSneUvoUx3",
    "outputId": "c30a4666-303f-47e4-9052-884b424b55a3"
   },
   "outputs": [],
   "source": [
    "#code to remove stop words from dataset\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "data['stemmed'].apply(lambda x: [item for item in x if item not in stop])\n",
    "data['tweet_without_stopwords'] = data['stemmed'].apply(lambda x: ' '.join([word for word in x if word not in (stop)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 1043,
     "status": "ok",
     "timestamp": 1604407877382,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "4h_I47JDpH2E"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>unstemmed</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>layin n bed with a headache  ughhhhwaitin on y...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[layin, n, bed, with, a, headache, ughhhhwaiti...</td>\n",
       "      <td>[layin, n, bed, with, a, headach, ughhhhwaitin...</td>\n",
       "      <td>layin n bed headach ughhhhwaitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>funeral ceremonygloomy friday</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[funeral, ceremonygloomy, friday]</td>\n",
       "      <td>[funer, ceremonygloomi, friday]</td>\n",
       "      <td>funer ceremonygloomi friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>repinging ghostridah14 why didnt you go to pro...</td>\n",
       "      <td>worry</td>\n",
       "      <td>[repinging, ghostridah14, why, didnt, you, go,...</td>\n",
       "      <td>[reping, ghostridah14, whi, didnt, you, go, to...</td>\n",
       "      <td>reping ghostridah14 whi didnt go prom bc bf di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>i should be sleep but im not thinking about an...</td>\n",
       "      <td>sadness</td>\n",
       "      <td>[i, should, be, sleep, but, im, not, thinking,...</td>\n",
       "      <td>[i, should, be, sleep, but, im, not, think, ab...</td>\n",
       "      <td>sleep im think old friend want hes marri damn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hmmm  is down</td>\n",
       "      <td>worry</td>\n",
       "      <td>[hmmm, is, down]</td>\n",
       "      <td>[hmmm, is, down]</td>\n",
       "      <td>hmmm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content sentiment  \\\n",
       "0  layin n bed with a headache  ughhhhwaitin on y...   sadness   \n",
       "1                      funeral ceremonygloomy friday   sadness   \n",
       "2  repinging ghostridah14 why didnt you go to pro...     worry   \n",
       "3  i should be sleep but im not thinking about an...   sadness   \n",
       "4                                      hmmm  is down     worry   \n",
       "\n",
       "                                           unstemmed  \\\n",
       "0  [layin, n, bed, with, a, headache, ughhhhwaiti...   \n",
       "1                  [funeral, ceremonygloomy, friday]   \n",
       "2  [repinging, ghostridah14, why, didnt, you, go,...   \n",
       "3  [i, should, be, sleep, but, im, not, thinking,...   \n",
       "4                                   [hmmm, is, down]   \n",
       "\n",
       "                                             stemmed  \\\n",
       "0  [layin, n, bed, with, a, headach, ughhhhwaitin...   \n",
       "1                    [funer, ceremonygloomi, friday]   \n",
       "2  [reping, ghostridah14, whi, didnt, you, go, to...   \n",
       "3  [i, should, be, sleep, but, im, not, think, ab...   \n",
       "4                                   [hmmm, is, down]   \n",
       "\n",
       "                             tweet_without_stopwords  \n",
       "0              layin n bed headach ughhhhwaitin call  \n",
       "1                        funer ceremonygloomi friday  \n",
       "2  reping ghostridah14 whi didnt go prom bc bf di...  \n",
       "3  sleep im think old friend want hes marri damn ...  \n",
       "4                                               hmmm  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 887
    },
    "executionInfo": {
     "elapsed": 1789,
     "status": "ok",
     "timestamp": 1604407884937,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "SBxsw1EmbJ23",
    "outputId": "c14b88eb-4bc2-4989-9516-3a4357bbf3d5"
   },
   "outputs": [],
   "source": [
    "#delete extra column\n",
    "del data['content']\n",
    "del data['unstemmed']\n",
    "del data['stemmed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tweet_without_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sadness</td>\n",
       "      <td>layin n bed headach ughhhhwaitin call</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>funer ceremonygloomi friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>worry</td>\n",
       "      <td>reping ghostridah14 whi didnt go prom bc bf di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sadness</td>\n",
       "      <td>sleep im think old friend want hes marri damn ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>worry</td>\n",
       "      <td>hmmm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sentiment                            tweet_without_stopwords\n",
       "0   sadness              layin n bed headach ughhhhwaitin call\n",
       "1   sadness                        funer ceremonygloomi friday\n",
       "2     worry  reping ghostridah14 whi didnt go prom bc bf di...\n",
       "3   sadness  sleep im think old friend want hes marri damn ...\n",
       "4     worry                                               hmmm"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 2800,
     "status": "ok",
     "timestamp": 1604407997674,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "W2W4c-XybJ3l"
   },
   "outputs": [],
   "source": [
    "#import require library for the data modelling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import string\n",
    "\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding, Dropout\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 2909,
     "status": "ok",
     "timestamp": 1604408003272,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "AeOS7W6XbJ3p"
   },
   "outputs": [],
   "source": [
    "# tokenize the string and convert into matrix\n",
    "tokenizer = Tokenizer(num_words=2000, split=\" \")\n",
    "tokenizer.fit_on_texts(data['tweet_without_stopwords'].values)\n",
    "\n",
    "X= tokenizer.texts_to_sequences(data['tweet_without_stopwords'].values)\n",
    "X = pad_sequences(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 1532,
     "status": "ok",
     "timestamp": 1604408015183,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "kt97xsAZbJ3t"
   },
   "outputs": [],
   "source": [
    "# one hot encoding the labels\n",
    "Y = pd.get_dummies(data['sentiment']).values\n",
    "#  divide into training and testing data\n",
    "import sklearn\n",
    "X_train,X_test,Y_train,Y_test = sklearn.model_selection.train_test_split(X,Y,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7054,
     "status": "ok",
     "timestamp": 1604408033227,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "wGxIrvf5bJ32",
    "outputId": "7493ab7a-6188-4ba7-d978-360de8035493"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 29, 256)           512000    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 29, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 29, 256)           525312    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 29, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 1,564,166\n",
      "Trainable params: 1,564,166\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# prepare the RNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 256, input_length=X_train.shape[1]))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, return_sequences=True, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(LSTM(256, dropout=0.5, recurrent_dropout=0.5))\n",
    "model.add(Dense(6, activation='softmax'))\n",
    "# compile the model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4901491,
     "status": "ok",
     "timestamp": 1604412943908,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "OlTzacs-bJ3_",
    "outputId": "102ac411-42f1-4d5c-c6ee-ca7343d461f4",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 1.5274 - accuracy: 0.3602\n",
      "Epoch 2/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 1.3531 - accuracy: 0.4570\n",
      "Epoch 3/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 1.3042 - accuracy: 0.4824\n",
      "Epoch 4/40\n",
      "612/612 [==============================] - 122s 200ms/step - loss: 1.2682 - accuracy: 0.5001\n",
      "Epoch 5/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 1.2438 - accuracy: 0.5120\n",
      "Epoch 6/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 1.2194 - accuracy: 0.5210\n",
      "Epoch 7/40\n",
      "612/612 [==============================] - 122s 200ms/step - loss: 1.2002 - accuracy: 0.5276\n",
      "Epoch 8/40\n",
      "612/612 [==============================] - 122s 200ms/step - loss: 1.1799 - accuracy: 0.5360\n",
      "Epoch 9/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 1.1617 - accuracy: 0.5426\n",
      "Epoch 10/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 1.1397 - accuracy: 0.5539\n",
      "Epoch 11/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 1.1238 - accuracy: 0.5590\n",
      "Epoch 12/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 1.1065 - accuracy: 0.5672\n",
      "Epoch 13/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 1.0800 - accuracy: 0.5773\n",
      "Epoch 14/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 1.0658 - accuracy: 0.5832\n",
      "Epoch 15/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 1.0476 - accuracy: 0.5930\n",
      "Epoch 16/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 1.0274 - accuracy: 0.5990\n",
      "Epoch 17/40\n",
      "612/612 [==============================] - 122s 200ms/step - loss: 1.0126 - accuracy: 0.6056\n",
      "Epoch 18/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 0.9996 - accuracy: 0.6081\n",
      "Epoch 19/40\n",
      "612/612 [==============================] - 123s 202ms/step - loss: 0.9832 - accuracy: 0.6151\n",
      "Epoch 20/40\n",
      "612/612 [==============================] - 124s 202ms/step - loss: 0.9643 - accuracy: 0.6227\n",
      "Epoch 21/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 0.9528 - accuracy: 0.6270\n",
      "Epoch 22/40\n",
      "612/612 [==============================] - 123s 200ms/step - loss: 0.9332 - accuracy: 0.6379\n",
      "Epoch 23/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 0.9234 - accuracy: 0.6409\n",
      "Epoch 24/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 0.9076 - accuracy: 0.6472\n",
      "Epoch 25/40\n",
      "612/612 [==============================] - 123s 200ms/step - loss: 0.8948 - accuracy: 0.6514\n",
      "Epoch 26/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.8772 - accuracy: 0.6548\n",
      "Epoch 27/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.8686 - accuracy: 0.6604\n",
      "Epoch 28/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.8593 - accuracy: 0.6631\n",
      "Epoch 29/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.8502 - accuracy: 0.6717\n",
      "Epoch 30/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.8398 - accuracy: 0.6725\n",
      "Epoch 31/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 0.8317 - accuracy: 0.6742\n",
      "Epoch 32/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 0.8127 - accuracy: 0.6803\n",
      "Epoch 33/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 0.8124 - accuracy: 0.6818\n",
      "Epoch 34/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 0.8053 - accuracy: 0.6848\n",
      "Epoch 35/40\n",
      "612/612 [==============================] - 123s 201ms/step - loss: 0.7926 - accuracy: 0.6921\n",
      "Epoch 36/40\n",
      "612/612 [==============================] - 121s 199ms/step - loss: 0.7814 - accuracy: 0.6955\n",
      "Epoch 37/40\n",
      "612/612 [==============================] - 121s 198ms/step - loss: 0.7769 - accuracy: 0.6947\n",
      "Epoch 38/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.7653 - accuracy: 0.7016\n",
      "Epoch 39/40\n",
      "612/612 [==============================] - 121s 197ms/step - loss: 0.7660 - accuracy: 0.7018\n",
      "Epoch 40/40\n",
      "612/612 [==============================] - 122s 199ms/step - loss: 0.7620 - accuracy: 0.7035\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8a5020beb8>"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model on training data\n",
    "batch_size = 50\n",
    "epochs = 40\n",
    "\n",
    "model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 2270,
     "status": "ok",
     "timestamp": 1604412946197,
     "user": {
      "displayName": "Bhavik Merai",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ght1uAPUmfJfN7ll1ToI-TM4u0WvSiI1gYLV3yXIig=s64",
      "userId": "07243453143499130543"
     },
     "user_tz": -660
    },
    "id": "Di3uGzcIbJ4F"
   },
   "outputs": [],
   "source": [
    "#save model on drive\n",
    "model.save('/content/drive/My Drive/emotion_detector/model_2/model2.h5')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Emotion_detector_V2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
